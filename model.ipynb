{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nav_menu": {
      "height": "381px",
      "width": "453px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YI_Vu_E3vuCR",
        "1OG9Fd04Q5Pl",
        "jWoERPMZIrpn",
        "-DMRzhTfvuFu",
        "Wdbo8RSyvuGC"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliAkbarBadri/pokemon-gan/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI_Vu_E3vuCR",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0R3wj1zDuC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation, Conv2DTranspose, Reshape, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageOps\n",
        "import glob\n",
        "import time\n",
        "import matplotlib.gridspec as gridspec\n",
        "from google.colab import files"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV3LMBLjEHBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "30533649-8469-4501-a2ef-9f4163cf7896"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGs4YyIgRLUy",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8redvFM6IeWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "data_dir = \"/content/drive/My Drive/gan/data\"\n",
        "\n",
        "for file in glob.glob(data_dir + '/*.png'):\n",
        "    img = Image.open(file)\n",
        "    jpg = img.convert('RGB')\n",
        "    jpg.save('./data/' + file.split('/')[-1].split('.')[0] + '.jpg')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjURlRP0H8in",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(image_shape, batch_size):\n",
        "    image_data_generator = ImageDataGenerator()\n",
        "    dataset_path = \"./data/\"\n",
        "    dataset_generator = image_data_generator.flow_from_directory(\n",
        "        dataset_path, target_size=(image_shape[0], image_shape[1]),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None)\n",
        "    return dataset_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPOD-xsSRF5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(generated_images, epoch_no, batch_no):\n",
        "    \"\"\"\n",
        "    Shows and saves generated images\n",
        "    :param generated_images:\n",
        "    :param epoch_no:\n",
        "    :param batch_no:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 8), num=2)\n",
        "    gs1 = gridspec.GridSpec(8, 8)\n",
        "    gs1.update(wspace=0, hspace=0)\n",
        "\n",
        "    for i in range(64):\n",
        "        ax1 = plt.subplot(gs1[i])\n",
        "        ax1.set_aspect('equal')\n",
        "        image = generated_images[i, :, :, :]\n",
        "        image += 1\n",
        "        image *= 127.5\n",
        "        fig = plt.imshow(image.astype(np.uint8))\n",
        "        plt.axis('off')\n",
        "        fig.axes.get_xaxis().set_visible(False)\n",
        "        fig.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_name = 'new_images/generated_epoch' + str(\n",
        "        epoch_no + 1) + '_batch' + str(batch_no + 1) + '.png'\n",
        "    if not os.path.exists('new_images'):\n",
        "        os.mkdir('new_images')\n",
        "    plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
        "    plt.pause(0.0000000001)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCeEgYlmRU4g",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hec5zUQRVCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model_mode):\n",
        "    \"\"\"\n",
        "    Train the GAN to generate images based on input data\n",
        "    \"\"\"\n",
        "    # generator: MLP, discriminator: MLP\n",
        "    if model_mode == \"mlp\":\n",
        "      generator = get_generator()\n",
        "      discriminator = get_discriminator()\n",
        "      gan = get_adversarial(generator, discriminator)\n",
        "    # generator: MLP, discriminator: CNN\n",
        "    elif model_mode == \"mlp_cnn\"\n",
        "      generator = get_generator()\n",
        "      discriminator = get_discriminator()\n",
        "      gan = get_adversarial(generator, discriminator)\n",
        "    # generator: CNN, discriminator: CNN\n",
        "    else:\n",
        "      generator = get_generator()\n",
        "      discriminator = get_discriminator()\n",
        "      gan = get_adversarial(generator, discriminator)\n",
        "\n",
        "    # Load dataset\n",
        "    dataset_generator = load_data()\n",
        "\n",
        "    number_of_batches = 150\n",
        "\n",
        "    # Variables that will be used to plot the losses from the discriminator and\n",
        "    # the adversarial models\n",
        "    adversarial_loss = np.empty(shape=1)\n",
        "    discriminator_loss = np.empty(shape=1)\n",
        "    batches = np.empty(shape=1)\n",
        "\n",
        "    # Allow plot updates inside for loop\n",
        "    plt.ion()\n",
        "\n",
        "    current_batch = 0\n",
        "\n",
        "    # Begin training\n",
        "    for epoch in range(self.epochs):\n",
        "\n",
        "        print(\"Epoch \" + str(epoch + 1) + \"/\" + str(self.epochs) + \" :\")\n",
        "\n",
        "        for batch_number in range(number_of_batches):\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            real_images = dataset_generator.next()\n",
        "\n",
        "            # Normalize the images between -1 and 1\n",
        "            real_images /= 127.5\n",
        "            real_images -= 1\n",
        "\n",
        "            # The last batch is smaller than the other ones, so we need to\n",
        "            # take that into account\n",
        "            current_batch_size = real_images.shape[0]\n",
        "\n",
        "            # Generate noise\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                      size=(current_batch_size,) + (1, 1, 100))\n",
        "\n",
        "            # Generate images\n",
        "            generated_images = generator.predict(noise)\n",
        "\n",
        "            # Add some noise to the labels that will be\n",
        "            # fed to the discriminator\n",
        "            real_y = (np.ones(current_batch_size) -\n",
        "                      np.random.random_sample(current_batch_size) * 0.2)\n",
        "            fake_y = np.random.random_sample(current_batch_size) * 0.2\n",
        "\n",
        "            # Let's train the discriminator\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            d_loss = discriminator.train_on_batch(real_images, real_y)\n",
        "            d_loss += discriminator.train_on_batch(generated_images, fake_y)\n",
        "\n",
        "            discriminator_loss = np.append(discriminator_loss, d_loss)\n",
        "\n",
        "            # Now it's time to train the generator\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                      size=(current_batch_size * 2,) +\n",
        "                                          (1, 1, 100))\n",
        "\n",
        "            # We try to mislead the discriminator by giving the opposite labels\n",
        "            fake_y = (np.ones(current_batch_size * 2) -\n",
        "                      np.random.random_sample(current_batch_size * 2) * 0.2)\n",
        "\n",
        "            g_loss = gan.train_on_batch(noise, fake_y)\n",
        "            adversarial_loss = np.append(adversarial_loss, g_loss)\n",
        "            batches = np.append(batches, current_batch)\n",
        "\n",
        "            # Each 50 batches show and save images\n",
        "            if ((batch_number + 1) % 50 == 0 and\n",
        "                    current_batch_size == self.batch_size):\n",
        "                self.save_images(generated_images, epoch, batch_number)\n",
        "\n",
        "            time_elapsed = time.time() - start_time\n",
        "\n",
        "            # Display and plot the results\n",
        "            print(\"     Batch \" + str(batch_number + 1) + \"/\" +\n",
        "                  str(number_of_batches) +\n",
        "                  \" generator loss | discriminator loss : \" +\n",
        "                  str(g_loss) + \" | \" + str(d_loss) + ' - batch took ' +\n",
        "                  str(time_elapsed) + ' s.')\n",
        "\n",
        "            current_batch += 1\n",
        "\n",
        "        # Save the model weights each 5 epochs\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            discriminator.trainable = True\n",
        "            if not os.path.exists('models'):\n",
        "                os.mkdir('models')\n",
        "            generator.save('models/generator_epoch' + str(epoch) + '.hdf5')\n",
        "            discriminator.save('models/discriminator_epoch' +\n",
        "                                str(epoch) + '.hdf5')\n",
        "\n",
        "        # Each epoch update the loss graphs\n",
        "        plt.figure(1)\n",
        "        plt.plot(batches, adversarial_loss, color='green',\n",
        "                  label='Generator Loss')\n",
        "        plt.plot(batches, discriminator_loss, color='blue',\n",
        "                  label='Discriminator Loss')\n",
        "        plt.title(\"GAN Training\")\n",
        "        plt.xlabel(\"Batch Iteration\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        if epoch == 0:\n",
        "            plt.legend()\n",
        "        plt.pause(0.0000000001)\n",
        "        plt.show()\n",
        "        plt.savefig('trainingLossPlot.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61QX6aXFbsGH",
        "colab_type": "text"
      },
      "source": [
        "# Model 1 (MLP, MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YynKCEL2buf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "codings_size = 30\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "gan = keras.models.Sequential([generator, discriminator])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bEk9Ai6byzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwpr0rU3b2Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4PBpIZhb4OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
        "    generator, discriminator = gan.layers\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))              \n",
        "        for X_batch in dataset:\n",
        "            # phase1 - training the discriminator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            generated_images = generator(noise)\n",
        "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "            # phase2 - training the generator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            y2 = tf.constant([[1.]] * batch_size)\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y2)\n",
        "        plot_multiple_images(generated_images, 8)                     \n",
        "        plt.show()                                                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZoIXU4b8u-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size, n_epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHJjpihGcAnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "generated_images = generator(noise)\n",
        "plot_multiple_images(generated_images, 8)\n",
        "save_fig(\"gan_generated_images_plot\", tight_layout=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3OLZWpucA_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdYATR1zcV_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import sys\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"gan\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNInRo5mbnB7",
        "colab_type": "text"
      },
      "source": [
        "# Model 2 (MLP, con2D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDUiizi-bnge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OG9Fd04Q5Pl",
        "colab_type": "text"
      },
      "source": [
        "# Model 3 (Conv2D, Conv2DTranspose)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJiCtwJcP8BS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator():\n",
        "    \"\"\"\n",
        "    This method returns a generator model that generates noise that will fool the discriminator.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    generator = Sequential()\n",
        "    generator.add(Dense(units=4 * 4 * 512,\n",
        "                        kernel_initializer='glorot_uniform',\n",
        "                        input_shape=(1, 1, 100)))\n",
        "    generator.add(Reshape(target_shape=(4, 4, 512)))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(Activation('tanh'))\n",
        "\n",
        "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "    generator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=None)\n",
        "\n",
        "    return generator\n",
        "\n",
        "def get_discriminator(image_shape):\n",
        "    \"\"\"\n",
        "    Learns to identify if a given image is similar to that of the training data or not\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    discriminator = Sequential()\n",
        "    discriminator.add(Conv2D(filters=64, kernel_size=(5, 5),\n",
        "                              strides=(2, 2), padding='same',\n",
        "                              data_format='channels_last',\n",
        "                              kernel_initializer='glorot_uniform',\n",
        "                              input_shape=image_shape))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=128, kernel_size=(5, 5),\n",
        "                              strides=(2, 2), padding='same',\n",
        "                              data_format='channels_last',\n",
        "                              kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=256, kernel_size=(5, 5),\n",
        "                              strides=(2, 2), padding='same',\n",
        "                              data_format='channels_last',\n",
        "                              kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=512, kernel_size=(5, 5),\n",
        "                              strides=(2, 2), padding='same',\n",
        "                              data_format='channels_last',\n",
        "                              kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Flatten())\n",
        "    discriminator.add(Dense(1))\n",
        "    discriminator.add(Activation('sigmoid'))\n",
        "\n",
        "    optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                          optimizer=optimizer,\n",
        "                          metrics=None)\n",
        "\n",
        "    return discriminator\n",
        "\n",
        "def get_adversarial(generator, discriminator):\n",
        "    gan = Sequential()\n",
        "    discriminator.trainable = False\n",
        "    gan.add(generator)\n",
        "    gan.add(discriminator)\n",
        "\n",
        "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
        "                metrics=None)\n",
        "    return gan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdbo8RSyvuGC",
        "colab_type": "text"
      },
      "source": [
        "# HOML Deep Convolutional GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJuUaHu6vuGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "codings_size = 100\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(7 * 7 * 128, input_shape=[codings_size]),\n",
        "    keras.layers.Reshape([7, 7, 128]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                                 activation=\"selu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                                 activation=\"tanh\"),\n",
        "])\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                        activation=keras.layers.LeakyReLU(0.2),\n",
        "                        input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                        activation=keras.layers.LeakyReLU(0.2)),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "gan = keras.models.Sequential([generator, discriminator])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULYOg4nXvuGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAJevR9BvuGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_dcgan = X_train.reshape(-1, 28, 28, 1) * 2. - 1. # reshape and rescale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "penUSf4LvuGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train_dcgan)\n",
        "dataset = dataset.shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmPzJQBdvuGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz9KTLh4vuGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "generated_images = generator(noise)\n",
        "plot_multiple_images(generated_images, 8)\n",
        "save_fig(\"dcgan_generated_images_plot\", tight_layout=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}