{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nav_menu": {
      "height": "381px",
      "width": "453px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YI_Vu_E3vuCR",
        "1OG9Fd04Q5Pl",
        "jWoERPMZIrpn",
        "-DMRzhTfvuFu",
        "Wdbo8RSyvuGC"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliAkbarBadri/pokemon-gan/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI_Vu_E3vuCR",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0R3wj1zDuC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation, Conv2DTranspose, Reshape, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageOps\n",
        "import glob\n",
        "import time\n",
        "import matplotlib.gridspec as gridspec\n",
        "from google.colab import files"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV3LMBLjEHBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c4e3268-a24b-4daf-a866-d6e6c74e9641"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGs4YyIgRLUy",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7fPmdaVk4Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir \"./data\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8redvFM6IeWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "data_dir = \"/content/drive/My Drive/nn/gan/data\"\n",
        "\n",
        "for file in glob.glob(data_dir + '/*.png'):\n",
        "    img = Image.open(file)\n",
        "    jpg = img.convert('RGB')\n",
        "    jpg.save('./data/' + file.split('/')[-1].split('.')[0] + '.jpg')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn2q4SSilnxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp -r \"./data/\" \"/content/drive/My Drive/nn/gan/data_jpg\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy3eUPQcKr5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "6272a586-8415-40b1-bb8f-f6eb86633f6b"
      },
      "source": [
        "! ls \"/content/drive/My Drive/nn/gan/data_jpg/\""
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.jpg\t 155.jpg  226.jpg  27.jpg   333.jpg  376.jpg  420.jpg  468.jpg\t5.jpg\n",
            "100.jpg  158.jpg  227.jpg  280.jpg  334.jpg  377.jpg  422.jpg  469.jpg\t61.jpg\n",
            "101.jpg  159.jpg  228.jpg  282.jpg  336.jpg  378.jpg  423.jpg  46.jpg\t63.jpg\n",
            "103.jpg  15.jpg   229.jpg  283.jpg  337.jpg  379.jpg  424.jpg  470.jpg\t64.jpg\n",
            "104.jpg  160.jpg  22.jpg   284.jpg  338.jpg  37.jpg   425.jpg  471.jpg\t65.jpg\n",
            "105.jpg  161.jpg  232.jpg  285.jpg  339.jpg  380.jpg  426.jpg  474.jpg\t66.jpg\n",
            "109.jpg  162.jpg  235.jpg  289.jpg  340.jpg  381.jpg  428.jpg  475.jpg\t67.jpg\n",
            "10.jpg\t 163.jpg  236.jpg  28.jpg   341.jpg  382.jpg  42.jpg   476.jpg\t68.jpg\n",
            "110.jpg  16.jpg   237.jpg  290.jpg  342.jpg  384.jpg  430.jpg  477.jpg\t69.jpg\n",
            "111.jpg  170.jpg  239.jpg  293.jpg  343.jpg  385.jpg  431.jpg  479.jpg\t70.jpg\n",
            "113.jpg  171.jpg  23.jpg   294.jpg  344.jpg  386.jpg  432.jpg  47.jpg\t71.jpg\n",
            "114.jpg  173.jpg  240.jpg  296.jpg  345.jpg  387.jpg  434.jpg  480.jpg\t73.jpg\n",
            "115.jpg  174.jpg  241.jpg  298.jpg  346.jpg  388.jpg  436.jpg  481.jpg\t75.jpg\n",
            "116.jpg  180.jpg  242.jpg  299.jpg  347.jpg  389.jpg  437.jpg  482.jpg\t76.jpg\n",
            "118.jpg  183.jpg  243.jpg  29.jpg   348.jpg  38.jpg   438.jpg  483.jpg\t77.jpg\n",
            "119.jpg  184.jpg  244.jpg  301.jpg  34.jpg   390.jpg  439.jpg  484.jpg\t7.jpg\n",
            "11.jpg\t 185.jpg  245.jpg  302.jpg  350.jpg  391.jpg  43.jpg   485.jpg\t80.jpg\n",
            "120.jpg  186.jpg  246.jpg  303.jpg  351.jpg  392.jpg  440.jpg  486.jpg\t81.jpg\n",
            "121.jpg  191.jpg  247.jpg  304.jpg  352.jpg  393.jpg  442.jpg  487.jpg\t83.jpg\n",
            "122.jpg  193.jpg  249.jpg  308.jpg  354.jpg  395.jpg  443.jpg  488.jpg\t84.jpg\n",
            "123.jpg  194.jpg  250.jpg  30.jpg   355.jpg  396.jpg  444.jpg  489.jpg\t87.jpg\n",
            "126.jpg  195.jpg  251.jpg  310.jpg  356.jpg  397.jpg  445.jpg  48.jpg\t88.jpg\n",
            "128.jpg  197.jpg  254.jpg  311.jpg  357.jpg  399.jpg  446.jpg  490.jpg\t89.jpg\n",
            "129.jpg  201.jpg  255.jpg  313.jpg  358.jpg  39.jpg   449.jpg  491.jpg\t90.jpg\n",
            "12.jpg\t 202.jpg  256.jpg  314.jpg  360.jpg  400.jpg  44.jpg   494.jpg\t91.jpg\n",
            "132.jpg  203.jpg  258.jpg  315.jpg  361.jpg  401.jpg  450.jpg  495.jpg\t94.jpg\n",
            "133.jpg  204.jpg  259.jpg  316.jpg  362.jpg  402.jpg  452.jpg  496.jpg\t95.jpg\n",
            "134.jpg  206.jpg  261.jpg  317.jpg  363.jpg  403.jpg  453.jpg  497.jpg\t96.jpg\n",
            "135.jpg  208.jpg  262.jpg  318.jpg  364.jpg  404.jpg  454.jpg  498.jpg\t97.jpg\n",
            "136.jpg  210.jpg  263.jpg  319.jpg  365.jpg  405.jpg  455.jpg  499.jpg\t98.jpg\n",
            "139.jpg  213.jpg  265.jpg  31.jpg   366.jpg  406.jpg  456.jpg  49.jpg\t99.jpg\n",
            "13.jpg\t 214.jpg  266.jpg  320.jpg  367.jpg  407.jpg  457.jpg  4.jpg\t9.jpg\n",
            "141.jpg  215.jpg  267.jpg  321.jpg  368.jpg  410.jpg  458.jpg  500.jpg\n",
            "143.jpg  216.jpg  268.jpg  322.jpg  369.jpg  411.jpg  459.jpg  501.jpg\n",
            "145.jpg  218.jpg  26.jpg   323.jpg  36.jpg   412.jpg  45.jpg   502.jpg\n",
            "148.jpg  219.jpg  272.jpg  324.jpg  370.jpg  413.jpg  461.jpg  51.jpg\n",
            "149.jpg  21.jpg   274.jpg  325.jpg  371.jpg  414.jpg  462.jpg  55.jpg\n",
            "14.jpg\t 221.jpg  275.jpg  326.jpg  372.jpg  415.jpg  463.jpg  56.jpg\n",
            "151.jpg  224.jpg  277.jpg  32.jpg   373.jpg  418.jpg  466.jpg  58.jpg\n",
            "153.jpg  225.jpg  279.jpg  331.jpg  375.jpg  419.jpg  467.jpg  59.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjURlRP0H8in",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(image_shape, batch_size):\n",
        "    image_data_generator = ImageDataGenerator()\n",
        "    dataset_path = \"/content/drive/My Drive/nn/gan/data_jpg/\"\n",
        "    dataset_generator = image_data_generator.flow_from_directory(\n",
        "        dataset_path, target_size=(image_shape[0], image_shape[1]),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None)\n",
        "    return dataset_generator"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q54dueoRLFHx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "704a0d15-c1fd-4c20-fdeb-46f3687763f3"
      },
      "source": [
        "dg = load_data(image_shape, batch_size)\n",
        "for id in range(5):\n",
        "  real_images = dg.next()\n",
        "  print(real_images)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2XBJj5KlIkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "781f74a9-8763-4e17-ad8e-8fef80f98deb"
      },
      "source": [
        "! mkdir \"./new_images\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./new_images’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPOD-xsSRF5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(generated_images, epoch_no, batch_no):\n",
        "    plt.figure(figsize=(8, 8), num=2)\n",
        "    gs1 = gridspec.GridSpec(8, 8)\n",
        "    gs1.update(wspace=0, hspace=0)\n",
        "\n",
        "    for i in range(64):\n",
        "        ax1 = plt.subplot(gs1[i])\n",
        "        ax1.set_aspect('equal')\n",
        "        image = generated_images[i, :, :, :]\n",
        "        image += 1\n",
        "        image *= 127.5\n",
        "        fig = plt.imshow(image.astype(np.uint8))\n",
        "        plt.axis('off')\n",
        "        fig.axes.get_xaxis().set_visible(False)\n",
        "        fig.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_name = 'new_images/generated_epoch' + str(\n",
        "        epoch_no + 1) + '_batch' + str(batch_no + 1) + '.png'\n",
        "    if not os.path.exists('new_images'):\n",
        "        os.mkdir('new_images')\n",
        "    plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
        "    plt.pause(0.0000000001)\n",
        "    plt.show()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lji6RCH99zUS",
        "colab_type": "text"
      },
      "source": [
        "# Model (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wdRg1MafNlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator(image_shape,codings_size=100):\n",
        "    generator = Sequential([\n",
        "      keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size],name=\"gen_dense1\"),\n",
        "      keras.layers.Dense(150, activation=\"selu\",name=\"gen_dense2\"),\n",
        "      keras.layers.Dense(image_shape[0] * image_shape[1]*image_shape[2], activation=\"tanh\",name=\"gen_dense3\"),\n",
        "      keras.layers.Reshape(image_shape,name=\"gen_reshape\")\n",
        "    ],name=\"GEN_MODEL\")\n",
        "    generator.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=None)\n",
        "    return generator\n",
        "\n",
        "def get_discriminator(image_shape):\n",
        "    discriminator = keras.models.Sequential([\n",
        "      keras.layers.Flatten(input_shape=image_shape,name=\"dis_flatten\"),\n",
        "      keras.layers.Dense(150, activation=\"selu\",name=\"dis_dense1\"),\n",
        "      keras.layers.Dense(100, activation=\"selu\",name=\"dis_dense2\"),\n",
        "      keras.layers.Dense(1, activation=\"sigmoid\",name=\"dis_dense3\")\n",
        "    ],name = \"DISC_MODEL\")\n",
        "    # discriminator.\n",
        "    # optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "    discriminator.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=None)\n",
        "    return discriminator\n",
        "\n",
        "def get_adversarial(generator, discriminator):\n",
        "    gan = Sequential()\n",
        "    discriminator.trainable = False\n",
        "    gan.add(generator)\n",
        "    gan.add(discriminator)\n",
        "\n",
        "    # optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=\"adam\",\n",
        "                metrics=None)\n",
        "    return gan"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCeEgYlmRU4g",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hec5zUQRVCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, batch_size, image_shape):\n",
        "    generator = get_generator(image_shape)\n",
        "    generator.summary()\n",
        "    discriminator = get_discriminator(image_shape)\n",
        "    discriminator.summary()\n",
        "    gan = get_adversarial(generator, discriminator)\n",
        "\n",
        "    # Load dataset\n",
        "    dataset_generator = load_data(image_shape, batch_size)\n",
        "\n",
        "    number_of_batches = 11\n",
        "\n",
        "    # Variables that will be used to plot the losses from the discriminator and\n",
        "    # the adversarial models\n",
        "    adversarial_loss = np.empty(shape=1)\n",
        "    discriminator_loss = np.empty(shape=1)\n",
        "    batches = np.empty(shape=1)\n",
        "\n",
        "    # Allow plot updates inside for loop\n",
        "    plt.ion()\n",
        "\n",
        "    current_batch = 0\n",
        "\n",
        "    # Begin training\n",
        "    g_loss_all = []\n",
        "    d_loss_all = []\n",
        "    for epoch in range(epochs):\n",
        "        g_loss_batch = []\n",
        "        d_loss_batch = []\n",
        "        start_time = time.time()\n",
        "        for batch_number in range(number_of_batches):\n",
        "            real_images = dataset_generator.next()\n",
        "            print(real_images)\n",
        "            break\n",
        "            # Normalize the images between -1 and 1\n",
        "            real_images /= 127.5\n",
        "            real_images -= 1\n",
        "            # The last batch is smaller than the other ones, so we need to\n",
        "            # take that into account\n",
        "            current_batch_size = real_images.shape[0]\n",
        "            # Generate noise\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                      size=(current_batch_size,) + (1, 1, 100)).reshape(current_batch_size,100)\n",
        "            # Generate images\n",
        "            generated_images = generator(noise)\n",
        "\n",
        "            # Add some noise to the labels that will be\n",
        "            # fed to the discriminator\n",
        "            # real_y = (np.ones(current_batch_size) -\n",
        "            #           np.random.random_sample(current_batch_size) * 0.2)\n",
        "            # fake_y = np.random.random_sample(current_batch_size) * 0.2\n",
        "\n",
        "            real_y = np.ones(current_batch_size)\n",
        "            fake_y = np.zeros(current_batch_size)\n",
        "\n",
        "            # y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            # y2 = tf.constant([[1.]] * batch_size)\n",
        "\n",
        "            # Let's train the discriminator\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            d_loss = discriminator.train_on_batch(real_images, real_y)\n",
        "            d_loss += discriminator.train_on_batch(generated_images, fake_y)\n",
        "            d_loss_batch.append(d_loss)\n",
        "            # discriminator_loss = np.append(discriminator_loss, d_loss)\n",
        "\n",
        "            # Now it's time to train the generator\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                      size=(current_batch_size * 2,) +\n",
        "                                          (1, 1, 100)).reshape(current_batch_size * 2,100)\n",
        "\n",
        "            # We try to mislead the discriminator by giving the opposite labels\n",
        "            # fake_y = (np.ones(current_batch_size * 2) -\n",
        "            #           np.random.random_sample(current_batch_size * 2) * 0.2)\n",
        "            fake_y = np.ones(current_batch_size * 2) \n",
        "            g_loss = gan.train_on_batch(noise, fake_y)\n",
        "            g_loss_batch.append(g_loss)\n",
        "            # adversarial_loss = np.append(adversarial_loss, g_loss)\n",
        "            batches = np.append(batches, current_batch)\n",
        "\n",
        "            # Each 50 batches show and save images\n",
        "            if ((batch_number + 1) % 50 == 0 and\n",
        "                    current_batch_size == batch_size):\n",
        "                save_images(generated_images, epoch, batch_number)\n",
        "\n",
        "            current_batch += 1\n",
        "\n",
        "            # if batch_number == number_of_batches-1:\n",
        "              # print(\"aaaaaaaa\",batch_number, number_of_batches)\n",
        "              # Display and plot the results\n",
        "        time_elapsed = time.time() - start_time\n",
        "        # print(\"generator loss: \"+str(np.mean(g_loss_batch))\n",
        "        #       + \" ,discriminator loss: \" + str(np.mean(d_loss_batch)) \n",
        "        #       + ' - epoch took ' + str(time_elapsed) + ' s.')\n",
        "        g_loss_all.append(np.mean(g_loss_batch))\n",
        "        d_loss_all.append(np.mean(d_loss_batch))\n",
        "        # Save the model weights each 5 epochs\n",
        "        # if (epoch + 1) % 5 == 0:\n",
        "        #     discriminator.trainable = True\n",
        "        #     if not os.path.exists('models'):\n",
        "        #         os.mkdir('models')\n",
        "        #     generator.save('models/generator_epoch' + str(epoch) + '.hdf5')\n",
        "        #     discriminator.save('models/discriminator_epoch' +\n",
        "        #                         str(epoch) + '.hdf5')\n",
        "        \n",
        "        # # Each epoch update the loss graphs\n",
        "    plt.figure(1)\n",
        "    plt.plot(range(epochs), g_loss_all, color='green',\n",
        "              label='Generator Loss')\n",
        "    plt.plot(range(epochs), d_loss_all, color='blue',\n",
        "              label='Discriminator Loss')\n",
        "    plt.title(\"GAN Training\")\n",
        "    plt.xlabel(\"Batch Iteration\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.pause(0.0000000001)\n",
        "    plt.show()\n",
        "        # plt.savefig('trainingLossPlot.png')\n",
        "    # print(\"-----\")\n",
        "    # print(len(g_loss_all))\n",
        "    # print(\"-----\")\n",
        "    # print(len(d_loss_all))"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLCb6PNHFsjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf02c821-ad24-4095-cc39-9f6ca9d407ec"
      },
      "source": [
        "data_size = 352\n",
        "batch_size = 32\n",
        "image_shape = (64, 64,3)\n",
        "coding_size = 100\n",
        "epochs = 200\n",
        "train(epochs, batch_size, image_shape)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"GEN_MODEL\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gen_dense1 (Dense)           (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "gen_dense2 (Dense)           (None, 150)               15150     \n",
            "_________________________________________________________________\n",
            "gen_dense3 (Dense)           (None, 12288)             1855488   \n",
            "_________________________________________________________________\n",
            "gen_reshape (Reshape)        (None, 64, 64, 3)         0         \n",
            "=================================================================\n",
            "Total params: 1,880,738\n",
            "Trainable params: 1,880,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"DISC_MODEL\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dis_flatten (Flatten)        (None, 12288)             0         \n",
            "_________________________________________________________________\n",
            "dis_dense1 (Dense)           (None, 150)               1843350   \n",
            "_________________________________________________________________\n",
            "dis_dense2 (Dense)           (None, 100)               15100     \n",
            "_________________________________________________________________\n",
            "dis_dense3 (Dense)           (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,858,551\n",
            "Trainable params: 1,858,551\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Found 0 images belonging to 0 classes.\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61QX6aXFbsGH",
        "colab_type": "text"
      },
      "source": [
        "# HOML Model 1 (MLP, MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YynKCEL2buf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "codings_size = 30\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "gan = keras.models.Sequential([generator, discriminator])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bEk9Ai6byzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwpr0rU3b2Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4PBpIZhb4OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
        "    generator, discriminator = gan.layers\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))              \n",
        "        for X_batch in dataset:\n",
        "            # phase1 - training the discriminator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            generated_images = generator(noise)\n",
        "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "            # phase2 - training the generator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            y2 = tf.constant([[1.]] * batch_size)\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y2)\n",
        "        plot_multiple_images(generated_images, 8)                     \n",
        "        plt.show()                                                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZoIXU4b8u-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size, n_epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHJjpihGcAnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "generated_images = generator(noise)\n",
        "plot_multiple_images(generated_images, 8)\n",
        "save_fig(\"gan_generated_images_plot\", tight_layout=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3OLZWpucA_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdYATR1zcV_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import sys\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"gan\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}