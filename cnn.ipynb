{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nav_menu": {
      "height": "381px",
      "width": "453px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YI_Vu_E3vuCR",
        "1OG9Fd04Q5Pl",
        "jWoERPMZIrpn",
        "-DMRzhTfvuFu",
        "Wdbo8RSyvuGC"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliAkbarBadri/pokemon-gan/blob/master/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI_Vu_E3vuCR",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0R3wj1zDuC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation, Conv2DTranspose, Reshape, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageOps\n",
        "import glob\n",
        "import time\n",
        "import matplotlib.gridspec as gridspec\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV3LMBLjEHBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c89e7657-1e68-41ab-a8a1-de79a2b99893"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGs4YyIgRLUy",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiRIOe3lHVjP",
        "colab_type": "text"
      },
      "source": [
        "## JPG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7fPmdaVk4Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir \"./data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8redvFM6IeWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "data_dir = \"/content/drive/My Drive/nn/gan/data\"\n",
        "\n",
        "for file in glob.glob(data_dir + '/*.png'):\n",
        "    img = Image.open(file)\n",
        "    jpg = img.convert('RGB')\n",
        "    jpg.save('./data/' + file.split('/')[-1].split('.')[0] + '.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy3eUPQcKr5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "a125d7ab-7f99-494e-db66-9c98e87d0873"
      },
      "source": [
        "! ls \"/content/drive/My Drive/nn/gan/data_jpg/0/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.jpg\t 155.jpg  226.jpg  27.jpg   333.jpg  376.jpg  420.jpg  468.jpg\t5.jpg\n",
            "100.jpg  158.jpg  227.jpg  280.jpg  334.jpg  377.jpg  422.jpg  469.jpg\t61.jpg\n",
            "101.jpg  159.jpg  228.jpg  282.jpg  336.jpg  378.jpg  423.jpg  46.jpg\t63.jpg\n",
            "103.jpg  15.jpg   229.jpg  283.jpg  337.jpg  379.jpg  424.jpg  470.jpg\t64.jpg\n",
            "104.jpg  160.jpg  22.jpg   284.jpg  338.jpg  37.jpg   425.jpg  471.jpg\t65.jpg\n",
            "105.jpg  161.jpg  232.jpg  285.jpg  339.jpg  380.jpg  426.jpg  474.jpg\t66.jpg\n",
            "109.jpg  162.jpg  235.jpg  289.jpg  340.jpg  381.jpg  428.jpg  475.jpg\t67.jpg\n",
            "10.jpg\t 163.jpg  236.jpg  28.jpg   341.jpg  382.jpg  42.jpg   476.jpg\t68.jpg\n",
            "110.jpg  16.jpg   237.jpg  290.jpg  342.jpg  384.jpg  430.jpg  477.jpg\t69.jpg\n",
            "111.jpg  170.jpg  239.jpg  293.jpg  343.jpg  385.jpg  431.jpg  479.jpg\t70.jpg\n",
            "113.jpg  171.jpg  23.jpg   294.jpg  344.jpg  386.jpg  432.jpg  47.jpg\t71.jpg\n",
            "114.jpg  173.jpg  240.jpg  296.jpg  345.jpg  387.jpg  434.jpg  480.jpg\t73.jpg\n",
            "115.jpg  174.jpg  241.jpg  298.jpg  346.jpg  388.jpg  436.jpg  481.jpg\t75.jpg\n",
            "116.jpg  180.jpg  242.jpg  299.jpg  347.jpg  389.jpg  437.jpg  482.jpg\t76.jpg\n",
            "118.jpg  183.jpg  243.jpg  29.jpg   348.jpg  38.jpg   438.jpg  483.jpg\t77.jpg\n",
            "119.jpg  184.jpg  244.jpg  301.jpg  34.jpg   390.jpg  439.jpg  484.jpg\t7.jpg\n",
            "11.jpg\t 185.jpg  245.jpg  302.jpg  350.jpg  391.jpg  43.jpg   485.jpg\t80.jpg\n",
            "120.jpg  186.jpg  246.jpg  303.jpg  351.jpg  392.jpg  440.jpg  486.jpg\t81.jpg\n",
            "121.jpg  191.jpg  247.jpg  304.jpg  352.jpg  393.jpg  442.jpg  487.jpg\t83.jpg\n",
            "122.jpg  193.jpg  249.jpg  308.jpg  354.jpg  395.jpg  443.jpg  488.jpg\t84.jpg\n",
            "123.jpg  194.jpg  250.jpg  30.jpg   355.jpg  396.jpg  444.jpg  489.jpg\t87.jpg\n",
            "126.jpg  195.jpg  251.jpg  310.jpg  356.jpg  397.jpg  445.jpg  48.jpg\t88.jpg\n",
            "128.jpg  197.jpg  254.jpg  311.jpg  357.jpg  399.jpg  446.jpg  490.jpg\t89.jpg\n",
            "129.jpg  201.jpg  255.jpg  313.jpg  358.jpg  39.jpg   449.jpg  491.jpg\t90.jpg\n",
            "12.jpg\t 202.jpg  256.jpg  314.jpg  360.jpg  400.jpg  44.jpg   494.jpg\t91.jpg\n",
            "132.jpg  203.jpg  258.jpg  315.jpg  361.jpg  401.jpg  450.jpg  495.jpg\t94.jpg\n",
            "133.jpg  204.jpg  259.jpg  316.jpg  362.jpg  402.jpg  452.jpg  496.jpg\t95.jpg\n",
            "134.jpg  206.jpg  261.jpg  317.jpg  363.jpg  403.jpg  453.jpg  497.jpg\t96.jpg\n",
            "135.jpg  208.jpg  262.jpg  318.jpg  364.jpg  404.jpg  454.jpg  498.jpg\t97.jpg\n",
            "136.jpg  210.jpg  263.jpg  319.jpg  365.jpg  405.jpg  455.jpg  499.jpg\t98.jpg\n",
            "139.jpg  213.jpg  265.jpg  31.jpg   366.jpg  406.jpg  456.jpg  49.jpg\t99.jpg\n",
            "13.jpg\t 214.jpg  266.jpg  320.jpg  367.jpg  407.jpg  457.jpg  4.jpg\t9.jpg\n",
            "141.jpg  215.jpg  267.jpg  321.jpg  368.jpg  410.jpg  458.jpg  500.jpg\n",
            "143.jpg  216.jpg  268.jpg  322.jpg  369.jpg  411.jpg  459.jpg  501.jpg\n",
            "145.jpg  218.jpg  26.jpg   323.jpg  36.jpg   412.jpg  45.jpg   502.jpg\n",
            "148.jpg  219.jpg  272.jpg  324.jpg  370.jpg  413.jpg  461.jpg  51.jpg\n",
            "149.jpg  21.jpg   274.jpg  325.jpg  371.jpg  414.jpg  462.jpg  55.jpg\n",
            "14.jpg\t 221.jpg  275.jpg  326.jpg  372.jpg  415.jpg  463.jpg  56.jpg\n",
            "151.jpg  224.jpg  277.jpg  32.jpg   373.jpg  418.jpg  466.jpg  58.jpg\n",
            "153.jpg  225.jpg  279.jpg  331.jpg  375.jpg  419.jpg  467.jpg  59.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81A8utdxHb9L",
        "colab_type": "text"
      },
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjURlRP0H8in",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(image_shape, batch_size):\n",
        "    image_data_generator = ImageDataGenerator()\n",
        "    dataset_path = \"/content/drive/My Drive/nn/gan/data_jpg/\"\n",
        "    dataset_generator = image_data_generator.flow_from_directory(\n",
        "        dataset_path, target_size=(image_shape[0], image_shape[1]),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None)\n",
        "    return dataset_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2XBJj5KlIkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir \"./new_images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPOD-xsSRF5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(generated_images, epoch_no, batch_no):\n",
        "    plt.figure(figsize=(8, 8), num=2)\n",
        "    gs1 = gridspec.GridSpec(8, 8)\n",
        "    gs1.update(wspace=0, hspace=0)\n",
        "\n",
        "    for i in range(64):\n",
        "        ax1 = plt.subplot(gs1[i])\n",
        "        ax1.set_aspect('equal')\n",
        "        image = generated_images[i, :, :, :]\n",
        "        image += 1\n",
        "        image *= 127.5\n",
        "        fig = plt.imshow(image.astype(np.uint8))\n",
        "        plt.axis('off')\n",
        "        fig.axes.get_xaxis().set_visible(False)\n",
        "        fig.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_name = 'new_images/generated_epoch' + str(\n",
        "        epoch_no + 1) + '_batch' + str(batch_no + 1) + '.png'\n",
        "    if not os.path.exists('new_images'):\n",
        "        os.mkdir('new_images')\n",
        "    plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
        "    plt.pause(0.0000000001)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lji6RCH99zUS",
        "colab_type": "text"
      },
      "source": [
        "# Model (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wdRg1MafNlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator(codings_size=100):\n",
        "        generator = Sequential(name=\"GEN_MODEL\")\n",
        "        generator.add(Dense(units=4 * 4 * 512,\n",
        "                            kernel_initializer='glorot_uniform',\n",
        "                            input_shape=[100], name=\"Dense1\"))\n",
        "        generator.add(Reshape(target_shape=(4, 4, 512),name=\"Reshape1\"))\n",
        "        generator.add(BatchNormalization(momentum=0.5,name=\"BN1\"))\n",
        "        generator.add(Activation('relu',name=\"relu1\"))\n",
        "\n",
        "        generator.add(Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
        "                                      strides=(2, 2), padding='same',\n",
        "                                      data_format='channels_last',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      name=\"C2DT2\"))\n",
        "        generator.add(BatchNormalization(momentum=0.5,name=\"BN2\"))\n",
        "        generator.add(Activation('relu',name=\"relu2\"))\n",
        "\n",
        "        generator.add(Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
        "                                      strides=(2, 2), padding='same',\n",
        "                                      data_format='channels_last',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      name=\"C2DT3\"))\n",
        "        generator.add(BatchNormalization(momentum=0.5,name=\"BN3\"))\n",
        "        generator.add(Activation('relu',name=\"relu3\"))\n",
        "\n",
        "        generator.add(Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
        "                                      strides=(2, 2), padding='same',\n",
        "                                      data_format='channels_last',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      name=\"C2DT4\"))\n",
        "        generator.add(BatchNormalization(momentum=0.5,name=\"BN4\"))\n",
        "        generator.add(Activation('relu',name=\"relu4\"))\n",
        "\n",
        "        generator.add(Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
        "                                      strides=(2, 2), padding='same',\n",
        "                                      data_format='channels_last',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      name=\"C2DT5\"))\n",
        "        \n",
        "        generator.add(Activation('tanh',name=\"tanh\"))\n",
        "        optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "        generator.compile(loss='binary_crossentropy',\n",
        "                          optimizer=optimizer,\n",
        "                          metrics=None)\n",
        "\n",
        "        return generator\n",
        "\n",
        "def get_discriminator(image_shape):\n",
        "        discriminator = Sequential()\n",
        "        discriminator.add(Conv2D(filters=64, kernel_size=(5, 5),\n",
        "                                 strides=(2, 2), padding='same',\n",
        "                                 data_format='channels_last',\n",
        "                                 kernel_initializer='glorot_uniform',\n",
        "                                 input_shape=image_shape))\n",
        "        discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "        discriminator.add(Conv2D(filters=128, kernel_size=(5, 5),\n",
        "                                 strides=(2, 2), padding='same',\n",
        "                                 data_format='channels_last',\n",
        "                                 kernel_initializer='glorot_uniform'))\n",
        "        discriminator.add(BatchNormalization(momentum=0.5))\n",
        "        discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "        discriminator.add(Conv2D(filters=256, kernel_size=(5, 5),\n",
        "                                 strides=(2, 2), padding='same',\n",
        "                                 data_format='channels_last',\n",
        "                                 kernel_initializer='glorot_uniform'))\n",
        "        discriminator.add(BatchNormalization(momentum=0.5))\n",
        "        discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "        discriminator.add(Conv2D(filters=512, kernel_size=(5, 5),\n",
        "                                 strides=(2, 2), padding='same',\n",
        "                                 data_format='channels_last',\n",
        "                                 kernel_initializer='glorot_uniform'))\n",
        "        discriminator.add(BatchNormalization(momentum=0.5))\n",
        "        discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "        discriminator.add(Flatten())\n",
        "        discriminator.add(Dense(1))\n",
        "        discriminator.add(Activation('sigmoid'))\n",
        "\n",
        "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "        discriminator.compile(loss='binary_crossentropy',\n",
        "                              optimizer=optimizer,\n",
        "                              metrics=None)\n",
        "\n",
        "        return discriminator\n",
        "\n",
        "\n",
        "def get_adversarial(generator, discriminator):\n",
        "    gan = Sequential()\n",
        "    discriminator.trainable = False\n",
        "    gan.add(generator)\n",
        "    gan.add(discriminator)\n",
        "\n",
        "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
        "                metrics=None)\n",
        "    return gan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCeEgYlmRU4g",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hec5zUQRVCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, batch_size, image_shape,number_of_batches=11):\n",
        "    generator = get_generator(image_shape)\n",
        "    generator.summary()\n",
        "    discriminator = get_discriminator(image_shape)\n",
        "    discriminator.summary()\n",
        "    gan = get_adversarial(generator, discriminator)\n",
        "\n",
        "    # Load dataset\n",
        "    dataset_generator = load_data(image_shape, batch_size)\n",
        "\n",
        "    # Variables that will be used to plot the losses from the discriminator and\n",
        "    # the adversarial models\n",
        "    batches = np.empty(shape=1)\n",
        "\n",
        "    # Allow plot updates inside for loop\n",
        "    plt.ion()\n",
        "\n",
        "    current_batch = 0\n",
        "\n",
        "    # Begin training\n",
        "    g_loss_all = []\n",
        "    d_loss_all = []\n",
        "    d_acc_all = []\n",
        "    for epoch in range(epochs):\n",
        "        g_loss_batch = []\n",
        "        d_loss_batch = []\n",
        "        d_acc_batch = []\n",
        "        start_time = time.time()\n",
        "        for batch_number in range(number_of_batches):\n",
        "            real_images = dataset_generator.next()\n",
        "\n",
        "            # Normalize the images between -1 and 1\n",
        "            real_images /= 127.5\n",
        "            real_images -= 1\n",
        "            # The last batch is smaller than the other ones, so we need to\n",
        "            # take that into account\n",
        "            current_batch_size = real_images.shape[0]\n",
        "            # Generate noise\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                      size=(current_batch_size,) + (1, 1, 100)).reshape(current_batch_size,100)\n",
        "            # Generate images\n",
        "            generated_images = generator(noise)\n",
        "\n",
        "            # Add some noise to the labels that will be fed to the discriminator\n",
        "            # real_y = (np.ones(current_batch_size) -\n",
        "            #           np.random.random_sample(current_batch_size) * 0.2)\n",
        "            # fake_y = np.random.random_sample(current_batch_size) * 0.2\n",
        "\n",
        "            real_y = np.ones(current_batch_size)\n",
        "            fake_y = np.zeros(current_batch_size)\n",
        "\n",
        "            # Let's train the discriminator\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            d_loss_real = discriminator.train_on_batch(real_images, real_y)\n",
        "            d_loss_fake = discriminator.train_on_batch(generated_images, fake_y)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "            d_loss_batch.append(d_loss[0])\n",
        "            d_acc_batch.append(d_loss[1])\n",
        "\n",
        "            # Now it's time to train the generator\n",
        "            discriminator.trainable = False\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                      size=(current_batch_size * 2,) +\n",
        "                                          (1, 1, 100)).reshape(current_batch_size * 2,100)\n",
        "\n",
        "            # We try to mislead the discriminator by giving the opposite labels\n",
        "            # fake_y = (np.ones(current_batch_size * 2) -\n",
        "            #           np.random.random_sample(current_batch_size * 2) * 0.2)\n",
        "            fake_y = np.ones(current_batch_size * 2) \n",
        "            g_loss = gan.train_on_batch(noise, fake_y)\n",
        "            g_loss_batch.append(g_loss)\n",
        "\n",
        "            # Each 32 batches show and save images\n",
        "            if epoch%5==0 and batch_number + 1 == 11:\n",
        "                save_images(generated_images, epoch, batch_number)\n",
        "            current_batch += 1\n",
        "        time_elapsed = time.time() - start_time\n",
        "        if epoch%5==0:\n",
        "          print(\"epoch: \"+str(epoch+1)+\", generator loss: \"+str(np.mean(g_loss_batch))\n",
        "                  + \", discriminator loss: \" + str(np.mean(d_loss_batch))\n",
        "                  + \", discriminator acc: \" + str(np.mean(d_acc_batch)) \n",
        "                  + ', epoch took ' + str(time_elapsed) + ' s.')\n",
        "        g_loss_all.append(np.mean(g_loss_batch))\n",
        "        d_loss_all.append(np.mean(d_loss_batch))\n",
        "        d_acc_all.append(np.mean(d_acc_batch))\n",
        "    generator.save('generator_mlp.h5')\n",
        "    discriminator.save('discriminator_mlp.h5')        \n",
        "    return g_loss_all, d_loss_all, d_acc_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLCb6PNHFsjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_size = 352\n",
        "batch_size = 32\n",
        "image_shape = (64, 64,3)\n",
        "coding_size = 100\n",
        "epochs = 100\n",
        "g_loss_all, d_loss_all = train(epochs, batch_size, image_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh9WCECBBayy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(range(epochs), g_loss_all, color='red')\n",
        "plt.title(\"Generator Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1aYn8_cBqEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(range(epochs), d_loss_all, color='green')\n",
        "plt.title(\"Discriminator Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BzKi_WoO05A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(range(epochs), d_acc_all, color='blue')\n",
        "plt.title(\"Discriminator Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}