{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nav_menu": {
      "height": "381px",
      "width": "453px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YI_Vu_E3vuCR",
        "1OG9Fd04Q5Pl",
        "jWoERPMZIrpn",
        "-DMRzhTfvuFu",
        "Wdbo8RSyvuGC"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliAkbarBadri/pokemon-gan/blob/master/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI_Vu_E3vuCR",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0R3wj1zDuC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation, Conv2DTranspose, Reshape, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageOps\n",
        "import glob\n",
        "import time\n",
        "import matplotlib.gridspec as gridspec\n",
        "from google.colab import files"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV3LMBLjEHBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c4e3268-a24b-4daf-a866-d6e6c74e9641"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGs4YyIgRLUy",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7fPmdaVk4Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir \"./data\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8redvFM6IeWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "data_dir = \"/content/drive/My Drive/nn/gan/data\"\n",
        "\n",
        "for file in glob.glob(data_dir + '/*.png'):\n",
        "    img = Image.open(file)\n",
        "    jpg = img.convert('RGB')\n",
        "    jpg.save('./data/' + file.split('/')[-1].split('.')[0] + '.jpg')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn2q4SSilnxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp -r \"./data/\" \"/content/drive/My Drive/nn/gan/data_jpg\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjURlRP0H8in",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(image_shape, batch_size):\n",
        "    image_data_generator = ImageDataGenerator()\n",
        "    dataset_path = \"/content/drive/My Drive/nn/gan/data_jpg\"\n",
        "    dataset_generator = image_data_generator.flow_from_directory(\n",
        "        dataset_path, target_size=(image_shape[0], image_shape[1]),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None)\n",
        "    return dataset_generator"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEb2X3VDuX-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in glob.glob(data_dir + '/*.png'):\n",
        "    img = Image.open(file)\n",
        "    jpg = img.convert('RGB')\n",
        "    jpg.save('./data/' + file.split('/')[-1].split('.')[0] + '.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2XBJj5KlIkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "781f74a9-8763-4e17-ad8e-8fef80f98deb"
      },
      "source": [
        "! mkdir \"./new_images\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./new_images’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPOD-xsSRF5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(generated_images, epoch_no, batch_no):\n",
        "    plt.figure(figsize=(8, 8), num=2)\n",
        "    gs1 = gridspec.GridSpec(8, 8)\n",
        "    gs1.update(wspace=0, hspace=0)\n",
        "\n",
        "    for i in range(64):\n",
        "        ax1 = plt.subplot(gs1[i])\n",
        "        ax1.set_aspect('equal')\n",
        "        image = generated_images[i, :, :, :]\n",
        "        image += 1\n",
        "        image *= 127.5\n",
        "        fig = plt.imshow(image.astype(np.uint8))\n",
        "        plt.axis('off')\n",
        "        fig.axes.get_xaxis().set_visible(False)\n",
        "        fig.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_name = 'new_images/generated_epoch' + str(\n",
        "        epoch_no + 1) + '_batch' + str(batch_no + 1) + '.png'\n",
        "    if not os.path.exists('new_images'):\n",
        "        os.mkdir('new_images')\n",
        "    plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
        "    plt.pause(0.0000000001)\n",
        "    plt.show()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wdRg1MafNlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator(image_shape,codings_size=100):\n",
        "    generator = Sequential([\n",
        "      keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size],name=\"gen_dense1\"),\n",
        "      keras.layers.Dense(150, activation=\"selu\",name=\"gen_dense2\"),\n",
        "      keras.layers.Dense(image_shape[0] * image_shape[1]*image_shape[2], activation=\"sigmoid\",name=\"gen_dense3\"),\n",
        "      keras.layers.Reshape(image_shape,name=\"gen_reshape\")\n",
        "    ],name=\"GEN_MODEL\")\n",
        "    # generator.compile(loss='binary_crossentropy',\n",
        "    #                   optimizer=\"rmsprop\",\n",
        "    #                   metrics=None)\n",
        "    # generator.\n",
        "    return generator\n",
        "\n",
        "def get_discriminator(image_shape):\n",
        "    discriminator = keras.models.Sequential([\n",
        "      keras.layers.Flatten(input_shape=image_shape,name=\"dis_flatten\"),\n",
        "      keras.layers.Dense(150, activation=\"selu\",name=\"dis_dense1\"),\n",
        "      keras.layers.Dense(100, activation=\"selu\",name=\"dis_dense2\"),\n",
        "      keras.layers.Dense(1, activation=\"sigmoid\",name=\"dis_dense3\")\n",
        "    ],name = \"DISC_MODEL\")\n",
        "    # discriminator.\n",
        "    # optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                          optimizer=\"rmsprop\",\n",
        "                          metrics=None)\n",
        "    return discriminator\n",
        "\n",
        "def get_adversarial(generator, discriminator):\n",
        "    gan = Sequential()\n",
        "    discriminator.trainable = False\n",
        "    gan.add(generator)\n",
        "    gan.add(discriminator)\n",
        "\n",
        "    # optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=\"rmsprop\",\n",
        "                metrics=None)\n",
        "    return gan"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU1LaNf_7Agk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7c7c96d-61fe-4f1d-f944-0d452028f6ce"
      },
      "source": [
        "temp = np.random.normal(0, 1, size=(32,) + (1, 1, 100))\n",
        "temp2 = np.random.normal(0, 1,\n",
        "                                      size=(32 * 2,) +\n",
        "                                          (1, 1, 100))\n",
        "temp3 = (np.ones(32 * 2) -\n",
        "                      np.random.random_sample(32 * 2) * 0.2)\n",
        "temp3.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCeEgYlmRU4g",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hec5zUQRVCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, batch_size, image_shape):\n",
        "    generator = get_generator(image_shape)\n",
        "    generator.summary()\n",
        "    discriminator = get_discriminator(image_shape)\n",
        "    discriminator.summary()\n",
        "    gan = get_adversarial(generator, discriminator)\n",
        "\n",
        "    # Load dataset\n",
        "    dataset_generator = load_data(image_shape, batch_size)\n",
        "\n",
        "    number_of_batches = 11\n",
        "\n",
        "    # Variables that will be used to plot the losses from the discriminator and\n",
        "    # the adversarial models\n",
        "    adversarial_loss = np.empty(shape=1)\n",
        "    discriminator_loss = np.empty(shape=1)\n",
        "    batches = np.empty(shape=1)\n",
        "\n",
        "    # Allow plot updates inside for loop\n",
        "    plt.ion()\n",
        "\n",
        "    current_batch = 0\n",
        "\n",
        "    # Begin training\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch \" + str(epoch + 1) + \"/\" + str(epochs) + \" :\")\n",
        "        # g_batch_loss = []\n",
        "        # d_batch_loss = []\n",
        "        for batch_number in range(number_of_batches):\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            real_images = dataset_generator.next()\n",
        "\n",
        "            # Normalize the images between -1 and 1\n",
        "            real_images /= 127.5\n",
        "            real_images -= 1\n",
        "\n",
        "            # The last batch is smaller than the other ones, so we need to\n",
        "            # take that into account\n",
        "            current_batch_size = real_images.shape[0]\n",
        "\n",
        "            # Generate noise\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                      size=(current_batch_size,) + (1, 1, 100)).reshape(current_batch_size,100)\n",
        "\n",
        "            # Generate images\n",
        "            # print(noise.shape)\n",
        "            generated_images = generator(noise)\n",
        "\n",
        "            # Add some noise to the labels that will be\n",
        "            # fed to the discriminator\n",
        "            real_y = (np.ones(current_batch_size) -\n",
        "                      np.random.random_sample(current_batch_size) * 0.2)\n",
        "            fake_y = np.random.random_sample(current_batch_size) * 0.2\n",
        "\n",
        "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            y2 = tf.constant([[1.]] * batch_size)\n",
        "\n",
        "            # Let's train the discriminator\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            d_loss = discriminator.train_on_batch(real_images, real_y)\n",
        "            d_loss += discriminator.train_on_batch(generated_images, fake_y)\n",
        "\n",
        "            discriminator_loss = np.append(discriminator_loss, d_loss)\n",
        "\n",
        "            # Now it's time to train the generator\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                      size=(current_batch_size * 2,) +\n",
        "                                          (1, 1, 100)).reshape(current_batch_size * 2,100)\n",
        "\n",
        "            # We try to mislead the discriminator by giving the opposite labels\n",
        "            fake_y = (np.ones(current_batch_size * 2) -\n",
        "                      np.random.random_sample(current_batch_size * 2) * 0.2)\n",
        "\n",
        "            g_loss = gan.train_on_batch(noise, fake_y)\n",
        "            adversarial_loss = np.append(adversarial_loss, g_loss)\n",
        "            batches = np.append(batches, current_batch)\n",
        "\n",
        "            # Each 50 batches show and save images\n",
        "            if ((batch_number + 1) % 50 == 0 and\n",
        "                    current_batch_size == batch_size):\n",
        "                save_images(generated_images, epoch, batch_number)\n",
        "\n",
        "            time_elapsed = time.time() - start_time\n",
        "\n",
        "            if batch_number == number_of_batches-1:\n",
        "              # print(\"aaaaaaaa\",batch_number, number_of_batches)\n",
        "              # Display and plot the results\n",
        "              print(\"     Batch \" + str(batch_number + 1) + \"/\" +\n",
        "                    str(number_of_batches) +\n",
        "                    \" generator loss | discriminator loss : \" +\n",
        "                    str(g_loss) + \" | \" + str(d_loss) + ' - batch took ' +\n",
        "                    str(time_elapsed) + ' s.')\n",
        "\n",
        "            current_batch += 1\n",
        "\n",
        "        # Save the model weights each 5 epochs\n",
        "        # if (epoch + 1) % 5 == 0:\n",
        "        #     discriminator.trainable = True\n",
        "        #     if not os.path.exists('models'):\n",
        "        #         os.mkdir('models')\n",
        "        #     generator.save('models/generator_epoch' + str(epoch) + '.hdf5')\n",
        "        #     discriminator.save('models/discriminator_epoch' +\n",
        "        #                         str(epoch) + '.hdf5')\n",
        "        \n",
        "        # # Each epoch update the loss graphs\n",
        "        # plt.figure(1)\n",
        "        # plt.plot(batches, adversarial_loss, color='green',\n",
        "        #           label='Generator Loss')\n",
        "        # plt.plot(batches, discriminator_loss, color='blue',\n",
        "        #           label='Discriminator Loss')\n",
        "        # plt.title(\"GAN Training\")\n",
        "        # plt.xlabel(\"Batch Iteration\")\n",
        "        # plt.ylabel(\"Loss\")\n",
        "        # if epoch == 0:\n",
        "        #     plt.legend()\n",
        "        # plt.pause(0.0000000001)\n",
        "        # plt.show()\n",
        "        # plt.savefig('trainingLossPlot.png')\n",
        "        "
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLCb6PNHFsjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "9bade79c-1a73-4973-bc7a-1e4bfa331f76"
      },
      "source": [
        "data_size = 352\n",
        "batch_size = 64\n",
        "image_shape = (64, 64,3)\n",
        "coding_size = 100\n",
        "epochs = 10\n",
        "train(epochs, batch_size, image_shape)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"GEN_MODEL\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gen_dense1 (Dense)           (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "gen_dense2 (Dense)           (None, 150)               15150     \n",
            "_________________________________________________________________\n",
            "gen_dense3 (Dense)           (None, 12288)             1855488   \n",
            "_________________________________________________________________\n",
            "gen_reshape (Reshape)        (None, 64, 64, 3)         0         \n",
            "=================================================================\n",
            "Total params: 1,880,738\n",
            "Trainable params: 1,880,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"DISC_MODEL\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dis_flatten (Flatten)        (None, 12288)             0         \n",
            "_________________________________________________________________\n",
            "dis_dense1 (Dense)           (None, 150)               1843350   \n",
            "_________________________________________________________________\n",
            "dis_dense2 (Dense)           (None, 100)               15100     \n",
            "_________________________________________________________________\n",
            "dis_dense3 (Dense)           (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,858,551\n",
            "Trainable params: 1,858,551\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Found 0 images belonging to 0 classes.\n",
            "Epoch 1/10 :\n",
            "     Batch 11/11 generator loss | discriminator loss : 0.0 | 0.0 - batch took 0.013945817947387695 s.\n",
            "Epoch 2/10 :\n",
            "     Batch 11/11 generator loss | discriminator loss : 0.0 | 0.0 - batch took 0.013633966445922852 s.\n",
            "Epoch 3/10 :\n",
            "     Batch 11/11 generator loss | discriminator loss : 0.0 | 0.0 - batch took 0.0158693790435791 s.\n",
            "Epoch 4/10 :\n",
            "     Batch 11/11 generator loss | discriminator loss : 0.0 | 0.0 - batch took 0.015233278274536133 s.\n",
            "Epoch 5/10 :\n",
            "     Batch 11/11 generator loss | discriminator loss : 0.0 | 0.0 - batch took 0.013999700546264648 s.\n",
            "Epoch 6/10 :\n",
            "     Batch 11/11 generator loss | discriminator loss : 0.0 | 0.0 - batch took 0.014301776885986328 s.\n",
            "Epoch 7/10 :\n",
            "     Batch 11/11 generator loss | discriminator loss : 0.0 | 0.0 - batch took 0.015786409378051758 s.\n",
            "Epoch 8/10 :\n",
            "     Batch 11/11 generator loss | discriminator loss : 0.0 | 0.0 - batch took 0.022744417190551758 s.\n",
            "Epoch 9/10 :\n",
            "     Batch 11/11 generator loss | discriminator loss : 0.0 | 0.0 - batch took 0.014040708541870117 s.\n",
            "Epoch 10/10 :\n",
            "     Batch 11/11 generator loss | discriminator loss : 0.0 | 0.0 - batch took 0.01598668098449707 s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61QX6aXFbsGH",
        "colab_type": "text"
      },
      "source": [
        "# HOML Model 1 (MLP, MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YynKCEL2buf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "codings_size = 30\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "gan = keras.models.Sequential([generator, discriminator])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bEk9Ai6byzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwpr0rU3b2Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4PBpIZhb4OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
        "    generator, discriminator = gan.layers\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))              \n",
        "        for X_batch in dataset:\n",
        "            # phase1 - training the discriminator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            generated_images = generator(noise)\n",
        "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "            # phase2 - training the generator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            y2 = tf.constant([[1.]] * batch_size)\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y2)\n",
        "        plot_multiple_images(generated_images, 8)                     \n",
        "        plt.show()                                                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZoIXU4b8u-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size, n_epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHJjpihGcAnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "generated_images = generator(noise)\n",
        "plot_multiple_images(generated_images, 8)\n",
        "save_fig(\"gan_generated_images_plot\", tight_layout=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3OLZWpucA_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdYATR1zcV_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import sys\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"gan\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}